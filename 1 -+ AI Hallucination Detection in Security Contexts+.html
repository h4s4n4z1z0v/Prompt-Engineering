<p><strong>“AI Hallucination Detection in Security Contexts”</strong>, created for AI governance leaders, security architects, red teams, and risk managers using <strong>Generative AI</strong> to assess and mitigate risks from <strong>inaccurate or fabricated AI-generated security outputs</strong>, commonly known as <strong>AI hallucinations</strong>.</p><p><br></p><p>1. “Generate a checklist to validate whether GenAI-generated security reports contain any unsupported claims or hallucinated IOCs.”</p><p><br></p><p>2. “Write a prompt to cross-reference AI-suggested MITRE ATT&amp;CK mappings with verified threat intelligence sources.”</p><p><br></p><p>3. “Create a validation workflow to detect hallucinated CVEs or fake exploit chains produced by AI summarization tools.”</p><p><br></p><p>4. “Simulate a scenario where an AI-generated risk assessment falsely attributes a vulnerability to a cloud service.”</p><p><br></p><p>5. “Generate a security SOP for detecting and correcting AI hallucinations in automatically generated incident reports.”</p><p><br></p><p>6. “Write a policy draft explaining how to use human-in-the-loop verification when using AI to generate SIEM correlation rules.”</p><p><br></p><p>7. “Design a hallucination detection prompt to compare AI-created firewall optimization suggestions with actual configuration files.”</p><p><br></p><p>8. “Create a side-by-side report that contrasts hallucinated IOC artifacts from GenAI with verified entries from MISP.”</p><p><br></p><p>9. “Generate a checklist to verify AI-generated penetration test summaries against raw scanner outputs (e.g., Nessus, Burp).”</p><p><br></p><p>10. “Simulate a hallucination scenario where AI suggests a non-existent attack technique in a threat modeling workshop.”</p><p><br></p><p>11. “Write a GenAI prompt to detect inconsistencies in AI-generated compliance documentation for ISO 27001.”</p><p><br></p><p>12. “Create a hallucination audit log template for documenting and reporting security hallucinations discovered post-use.”</p><p><br></p><p>13. “Generate a table comparing hallucinated C2 domains from AI outputs vs. threat intel databases like VirusTotal and AlienVault OTX.”</p><p><br></p><p>14. “Simulate a GenAI assistant providing fabricated guidance on IAM hardening in AWS and generate the correct remediation.”</p><p><br></p><p>15. “Write a test case to evaluate hallucination risk in AI-generated phishing simulation emails.”</p><p><br></p><p>16. “Generate a briefing note to CISOs on AI hallucination risks in GenAI-assisted vulnerability prioritization workflows.”</p><p><br></p><p>17. “Create a validation protocol for AI-generated playbooks in SOAR platforms to ensure only executable steps are included.”</p><p><br></p><p>18. “Write a prompt that checks AI-generated threat actor profiles for references to non-existent APT groups or campaigns.”</p><p><br></p><p>19. “Develop an automated hallucination detection mechanism for LLM-generated code snippets embedded in security runbooks.”</p><p><br></p><p>20. “Simulate an enterprise risk scenario where AI hallucination leads to a misinformed decision on threat mitigation.”</p>